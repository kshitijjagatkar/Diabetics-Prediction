{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pima Indian Diabetics Prediction\n",
    "     \n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. I collected this data from kaggle, for the link click [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database)\n",
    "\n",
    "#### Curiosity \n",
    "\n",
    "I choose this data for predicting if a person has a diabetes or not but without using any Machine Learning library. I was having a curiosity of solving this problem by using mathematics and the data analysis libraries. Achieving the great accuracy is not my goal here but to chase the curiosity.\n",
    "\n",
    "To make good Structure I followed follwing path:\n",
    "\n",
    " 1. Data Understanding\n",
    " 2. Data Preparation\n",
    " 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     # import data analysis libraries\n",
    "import numpy as np\n",
    "\n",
    "from math import exp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(r\"E:\\Study\\Projects\\diabetes\\diabetes.csv\") # Read file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns  # Columns list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta:(9, 1), X:(768, 9), Y:(768, 1)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the input variable(X), output variable(Y) and also theta.\n",
    "\n",
    "# Collect all data for the input variable\n",
    "X = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']].values\n",
    "\n",
    "#here, we are adding one extra column containing only one's to the input(X) using np.c_ method\n",
    "X=np.c_[np.ones(len(X)),X]\n",
    "\n",
    " # giving the shape of X to m and n(m will contain rows and n columns)\n",
    "[m,n]=X.shape\n",
    "\n",
    " # Making theta's of zero's of the shape(n*1)\n",
    "theta=np.array(np.zeros((n,1)))\n",
    "\n",
    "# Make output varible y containing predicting values.\n",
    "Y=df['Outcome'].values\n",
    "Y=np.reshape(Y,(m,1)) #reshaping into m*1 size\n",
    "\n",
    "print(\"theta:{0}, X:{1}, Y:{2}\".format(theta.shape,X.shape,Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846.0 0.0 40.0984810474537\n",
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Normalize our features\n",
    "\n",
    "Xmax, Xmin = X.max(), X.min() # calculate max and min\n",
    "Xavg=np.average(X) #calculate average\n",
    "print(Xmax,Xmin,Xavg)\n",
    "\n",
    "X=(X-Xavg) / Xmax-Xmin # normalizing \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothesis shape (768, 1)\n"
     ]
    }
   ],
   "source": [
    "#Since we are using logistic regression so calculating the sgmoid function.\n",
    "\n",
    "def sigmoid(X,theta):\n",
    "        \"\"\" Here, we are calculating the sigmoid function as it maps the whole\n",
    "            range of z values(z = theta.T * X) into [0,1] in g(z) = 1/1+e^-z.\n",
    "            cause our goal is to classify the output in  o or 1 that's why sigmoid \n",
    "            function plays big role here.\"\"\"\n",
    "        \n",
    "        hyp = 1 + np.exp(-np.dot(X,theta)) # calculating hypothesis (1+e^z)\n",
    "        hx= np.divide(1,hyp) \n",
    "        return hx\n",
    "    \n",
    "hx=sigmoid(X,theta)   \n",
    "print(\"hypothesis shape\",hx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost function [[0.69314718]]\n"
     ]
    }
   ],
   "source": [
    "# Calculating Cost Function\n",
    "\n",
    "def costf(X,Y):\n",
    "        \"\"\" Here, we are calculating the cost function the error between predicted and expected values\n",
    "             cost = -1/m[y log(hx)+(1-y)log(1-hx)]\n",
    "        \"\"\"\n",
    "        cost = np.dot(Y.T, np.log(hx)) + np.dot((1-Y).T, np.log(1-hx))\n",
    "        jtheta = np.dot((-1/m),cost)\n",
    "        \n",
    "        return jtheta\n",
    "\n",
    "jtheta = costf(X,Y)\n",
    "print(\"Cost function\", jtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient discent - minimizing cost function(jtheta)\n",
    "\n",
    "def grad(X,Y,hx):\n",
    "    \"\"\"To minimize the cost here we are calculating gredient descent\n",
    "        first we created the thetaj gradient variable to save our descent.\n",
    "        our descents: thetaj:= thetaj - 1/m (hx-y) xj. xj are the features.\"\"\"\n",
    "    \n",
    "    thetaj=np.array(np.zeros(theta.shape))\n",
    "    thetaj+=thetaj-np.divide(np.sum(np.dot(X.T,hx-Y)),m)\n",
    "    \n",
    "    return thetaj\n",
    "        \n",
    "final_theta=grad(X,Y,hx)\n",
    "\n",
    "print(final_theta.shape)\n",
    "final_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained accuracy:\n",
      " 64.32291666666666\n"
     ]
    }
   ],
   "source": [
    "#Finding_Accuracy\n",
    "\n",
    "p=sigmoid(X,final_theta)>=0.5\n",
    "\n",
    "print(\"trained accuracy:\\n\", np.mean(p==Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" To do something a bit more we can do one thing is that \n",
    "    adding some more features from existing features in this way we can traing some more features\n",
    "    and add a bit accuracy to our model.\n",
    "    Here we have taken two features X1 and X2 and making other more features from these two features\n",
    "\"\"\"\n",
    "\n",
    "X1=np.mat([X[:,0]]).T  # Extracted two features\n",
    "X2=np.mat([X[:,1]]).T\n",
    "\n",
    "out=np.ones((m,1))  # an empty array of one's\n",
    "\n",
    "degree=6\n",
    "\n",
    "for i in np.arange(0,6):\n",
    "    for j in np.arange(0,i):\n",
    "        out = np.multiply(np.power(X1,(i-j)),np.power(X2,j)) # creating new features from existing ones\n",
    "        X = np.c_[(X,out)]  \n",
    "        \n",
    "[m,n]=X.shape\n",
    "theta=np.array(np.zeros((n,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam=1000 #lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Cost function regularised\n",
    "\n",
    "def costf_reg(X,Y,theta):\n",
    "    \"\"\"Since we added many features we should regularised. It make trade off \n",
    "        between the hx and regularization term for making hypothesis simple and avoid overfitting.\n",
    "            j(theta) = 1/m [y log(hx) + (1-y)log(1-hx)] + lambda/2m theta^2 \"\"\"\n",
    "    \n",
    "    cost= np.dot(Y.T,np.log(hx))+np.dot((1-Y).T,np.log(1-hx))\n",
    "    cost_reg= np.dot(np.divide(lam,2*m),np.sum(np.square(theta[1:])))\n",
    "    jtheta= np.dot((-1/m),cost)+cost_reg\n",
    "    \n",
    "    return jtheta\n",
    "\n",
    "jtheta = costf_reg(X,Y,theta)\n",
    "print(\"Cost shape:\",jtheta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.03\n",
    "epoch=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164],\n",
       "       [0.02158164]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grad_reg(X,Y,hx,alpha,epoch):\n",
    "    \"\"\" Calculating gredient descent for regularization term\n",
    "        Note that we do not regularize theta0. for j=0 the descent is in else statement and for j>=1\n",
    "        descent is in if statement.\n",
    "        for j=0; thetaj:=thetaj - alpha 1/m (h(x)-y) xj)\n",
    "        for j>=1 thetaj:=thetaj - alpha[1/m (h(x)-y) xj) + lambda/m theta ]\"\"\"\n",
    "    thetaj=np.array(np.zeros(theta.shape))\n",
    "    \n",
    "    for epoch in range(epoch):\n",
    "        for j in range(0,len(theta)):\n",
    "            if(j!=0):\n",
    "                thetaj[j]+=thetaj[j]- np.dot(np.divide(np.sum(np.dot(X.T,hx-Y)),m)+ np.dot(np.divide(lam,m),theta[j]),alpha)\n",
    "            else:\n",
    "                thetaj[j]+=thetaj[j]- np.dot(np.divide(np.sum(np.dot(X.T,hx-Y)),m),alpha)\n",
    "    \n",
    "    \n",
    "    return thetaj\n",
    "        \n",
    "final_theta_reg=grad_reg(X,Y,hx,alpha,epoch)\n",
    "print(final_theta.shape)\n",
    "final_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained accuracy:\n",
      " 65.36458333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kshitij\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Finding_probabilty\n",
    "\n",
    "p=sigmoid(X,final_theta_reg)>=0.5\n",
    "print(\"trained accuracy:\\n\", np.mean(p==Y)*100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def sgd(X,Y,hx):\n",
    "        \n",
    "        \"\"\"Trying out with another algorithm called stochastic gredient descent for better efficiancy\n",
    "            #b = b + learning_rate * (y - hx) * hx * (1 - hx) * x \"\"\"\n",
    "        b=np.array(np.zeros(theta.shape))\n",
    "        b+= b + np.dot(alpha,np.dot(np.dot(X.T,(1-hx)),np.dot((Y-hx).T,hx)))\n",
    "        return b\n",
    "theta_sgd=sgd(X,Y,hx)\n",
    "theta_sgd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained accuracy:\n",
      " 65.10416666666666\n"
     ]
    }
   ],
   "source": [
    "#Finding_probabilty\n",
    "\n",
    "p=sigmoid(X,theta_sgd)>=0.5\n",
    "print(\"trained accuracy:\\n\", np.mean(p==Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm, so we looked at the whole process in simple manner. there are lots of things we can do to improve more like in the data preparation step we can play more with the data so by that we will get more better results and also by trying out some different algorithms. like here we used sgd algo and withount making lot of work it predicted wel. if our data would be clean as possible then this algo might gives us different result.\n",
    "\n",
    "So there you go with implementation of logistic algorithm with and without regularization term also the sgd algorithm for predicting if a patient has diabeties or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
